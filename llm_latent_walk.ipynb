{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: ! peaceful village rests by the lake.!\n",
      "Step 1: ! peaceful village rests by the lake.!\n",
      "Step 2: ! peaceful village rests by the lake.!\n",
      "Step 3: ! peaceful village rests by the lake.!\n",
      "Step 4: ! peaceful village rests by the lake.!\n",
      "Step 5: ! peaceful village rests by the lake.!\n",
      "Step 6: ! peaceful village restsows the lake.!\n",
      "Step 7: ! peaceful village restsows the lake.!\n",
      "Step 8: ! peaceful village restsows the lake.!\n",
      "Step 9: ! peaceful village restsows the lake.!\n",
      "Step 10: ! peaceful village restsows the lake.!\n",
      "Step 11: ! peaceful village restsows the lake.!\n",
      "Step 12: ! peaceful village restsows the lake lights!\n",
      "Step 13: ! peaceful village restsows the lake lights!\n",
      "Step 14: ! peaceful village restsows under neon lights!\n",
      "Step 15: ! futuristic village restsows under neon lights!\n",
      "Step 16: ! futuristic village restsows under neon lights!\n",
      "Step 17: ! futuristic village restsows under neon lights!\n",
      "Step 18: ! futuristic city restsows under neon lights!\n",
      "Step 19: ! futuristic city glows under neon lights!\n",
      "Step 20: ! futuristic city glows under neon lights!\n",
      "Step 21: ! futuristic city glows under neon lights!\n",
      "Step 22: ! futuristic city glows under neon lights!\n",
      "Step 23: ! futuristic city glows under neon lights!\n",
      "Step 24: ! futuristic city glows under neon lights!\n",
      "Step 25: ! futuristic city glows under neon lights!\n",
      "Step 26: ! futuristic city glows under neon lights!\n",
      "Step 27: ! futuristic city glows under neon lights!\n",
      "Step 28: ! futuristic city glows under neon lights!\n",
      "Step 29: ! futuristic city glows under neon lights!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52636/3160894687.py:33: RuntimeWarning: invalid value encountered in divide\n",
      "  dot = np.sum(v0 * v1, axis=-1) / (np.linalg.norm(v0, axis=-1) * np.linalg.norm(v1, axis=-1))\n",
      "/tmp/ipykernel_52636/3160894687.py:40: RuntimeWarning: invalid value encountered in divide\n",
      "  v = (np.sin((1 - t) * theta) / sin_theta)[:, None] * v0 + (np.sin(t * theta) / sin_theta)[:, None] * v1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# walk between 2 sentences in the latent space of a pretrained GPT-2 model\n",
    "\n",
    "# Load GPT-2 with the language modeling head\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Define two input sentences\n",
    "sentence1 = \"A peaceful village rests by the lake.\"\n",
    "sentence2 = \"A futuristic city glows under neon lights.\"\n",
    "\n",
    "# Convert sentences into embeddings\n",
    "tokens1 = tokenizer(sentence1, return_tensors=\"pt\")[\"input_ids\"]\n",
    "tokens2 = tokenizer(sentence2, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "# Get word embeddings\n",
    "with torch.no_grad():\n",
    "    embedding1 = model.get_input_embeddings()(tokens1).squeeze(0)\n",
    "    embedding2 = model.get_input_embeddings()(tokens2).squeeze(0)\n",
    "\n",
    "# Ensure embeddings have the same length (pad if necessary)\n",
    "max_len = max(embedding1.shape[0], embedding2.shape[0])\n",
    "embedding1 = torch.nn.functional.pad(embedding1, (0, 0, 0, max_len - embedding1.shape[0]))\n",
    "embedding2 = torch.nn.functional.pad(embedding2, (0, 0, 0, max_len - embedding2.shape[0]))\n",
    "\n",
    "# Define SLERP function (Spherical Linear Interpolation)\n",
    "# change num steps \n",
    "def slerp(v0, v1, num_steps=10):\n",
    "    v0, v1 = v0.numpy(), v1.numpy()\n",
    "    dot = np.sum(v0 * v1, axis=-1) / (np.linalg.norm(v0, axis=-1) * np.linalg.norm(v1, axis=-1))\n",
    "    dot = np.clip(dot, -1.0, 1.0)\n",
    "    theta = np.arccos(dot)\n",
    "    sin_theta = np.sin(theta)\n",
    "\n",
    "    interpolated_vectors = []\n",
    "    for t in np.linspace(0, 1, num_steps):\n",
    "        v = (np.sin((1 - t) * theta) / sin_theta)[:, None] * v0 + (np.sin(t * theta) / sin_theta)[:, None] * v1\n",
    "        interpolated_vectors.append(torch.tensor(v, dtype=torch.float32))\n",
    "\n",
    "    return interpolated_vectors\n",
    "\n",
    "# Generate interpolated latents\n",
    "num_steps = 30\n",
    "interpolated_latents = slerp(embedding1, embedding2, num_steps=num_steps)\n",
    "\n",
    "# Decode the interpolated embeddings into words\n",
    "decoded_sentences = []\n",
    "for i, latent in enumerate(interpolated_latents):\n",
    "    with torch.no_grad():\n",
    "        token_logits = model.lm_head(latent)  # âœ… Now works with `AutoModelForCausalLM`\n",
    "        token_ids = torch.argmax(token_logits, dim=-1)\n",
    "        decoded_text = tokenizer.decode(token_ids, skip_special_tokens=True)\n",
    "    \n",
    "    decoded_sentences.append(decoded_text)\n",
    "    print(f\"Step {i}: {decoded_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get answer to a question and walk around the answer randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
